name: Hourly Update and Deploy

on:
  schedule:
    # Run every hour
    - cron: '0 * * * *'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write
  pages: write
  id-token: write

# Allow one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  update-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install UV
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install Python dependencies
        run: uv sync --all-extras

      # ========================================================================
      # DISCOVER NEW GAMES AND ENRICH METADATA (once per day at 8 AM UTC)
      # ========================================================================

      - name: Discover new games and enrich metadata (daily at 8 AM UTC)
        env:
          IGDB_CLIENT_ID: ${{ secrets.IGDB_CLIENT_ID }}
          IGDB_CLIENT_SECRET: ${{ secrets.IGDB_CLIENT_SECRET }}
        run: |
          HOUR=$(date -u +%H)
          if [ "$HOUR" = "08" ]; then
            echo "üîç Discovering new games from multiple sources..."
            uv run python -m python.main discover \
              --top-limit 200 \
              --trending-limit 100
            echo "‚úÖ Game discovery complete"

            echo "üéØ Enriching game metadata from IGDB..."
            uv run python -m python.main metadata
            echo "‚úÖ Metadata enrichment complete"
          else
            echo "‚è≠Ô∏è  Skipping discovery and enrichment (runs only at 8 AM UTC, current hour: $HOUR)"
          fi

      # ========================================================================
      # COLLECT DATA FROM MULTIPLE SOURCES (SEQUENTIAL)
      # ========================================================================
      # Note: DuckDB doesn't support concurrent writes, so we run sequentially

      - name: Collect Steam data
        run: |
          echo "üéÆ Starting Steam collection..."
          uv run python -m python.main collect steam
          echo "‚úÖ Steam collection complete"

      - name: Collect Twitch data
        env:
          TWITCH_CLIENT_ID: ${{ secrets.TWITCH_CLIENT_ID }}
          TWITCH_CLIENT_SECRET: ${{ secrets.TWITCH_CLIENT_SECRET }}
        run: |
          echo "üì∫ Starting Twitch collection..."
          uv run python -m python.main collect twitch
          echo "‚úÖ Twitch collection complete"

      # ========================================================================
      # AGGREGATE KPIs (ALL SOURCES)
      # ========================================================================
      # Note: Data is already in DuckDB (inserted during collection)

      - name: Aggregate KPIs and generate rankings
        run: |
          echo "üìä Aggregating KPIs from all sources..."
          uv run python -m python.main aggregate
          echo "‚úÖ KPIs aggregated and rankings generated"

      # ========================================================================
      # BUILD OBSERVABLE DASHBOARD
      # ========================================================================

      - name: Set up Node.js for Observable Framework
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Observable Framework
        run: npm ci

      - name: Build static site
        run: npm run build

      # ========================================================================
      # DEPLOY TO GITHUB PAGES
      # ========================================================================

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./dist

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      # ========================================================================
      # COMMIT DATA TO REPOSITORY
      # ========================================================================

      - name: Commit collected data
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          # Add new data files from all sources
          git add data/raw/steam/ data/raw/twitch/ data/duckdb/ src/data/

          if git diff --staged --quiet; then
            echo "üì≠ No new data to commit"
          else
            TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")
            git commit -m "data: hourly update ${TIMESTAMP}"
            git push
            echo "‚úÖ Data committed and pushed"
          fi
