name: Hourly Data Collection

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write # Required for committing data

jobs:
  collect:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true # Enable Git LFS
          fetch-depth: 0

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install UV
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Collect Steam data
        run: |
          echo "ğŸ® Collecting Steam data for top 10 games..."
          uv run python -m python.main collect --output data/raw/steam --limit 10

      - name: Load data into DuckDB
        run: |
          echo "ğŸ’¾ Loading Parquet files into DuckDB..."
          uv run python -c "
          from pathlib import Path
          import pandas as pd
          from python.storage.duckdb_manager import DuckDBManager

          db_path = Path('data/duckdb/gaming.db')

          with DuckDBManager(db_path=db_path) as db:
              # Find all parquet files from today's collection
              parquet_files = sorted(
                  Path('data/raw/steam').rglob('*.parquet'),
                  key=lambda p: p.stat().st_mtime
              )

              if parquet_files:
                  # Load the most recent files (today's collection)
                  recent_files = [f for f in parquet_files if (Path.cwd() / f).stat().st_mtime > (pd.Timestamp.now() - pd.Timedelta(hours=2)).timestamp()]

                  for pf in recent_files:
                      df = pd.read_parquet(pf)
                      db.append_data(df, table_name='steam_raw')

                  print(f'âœ… Loaded {len(recent_files)} new Parquet files into DuckDB')
              else:
                  print('âš ï¸  No new Parquet files found')
          "

      - name: Cleanup old data (30-day retention)
        run: |
          echo "ğŸ§¹ Cleaning up Parquet files older than 30 days..."
          uv run python -c "
          from pathlib import Path
          from python.utils.cleanup import cleanup_old_data

          result = cleanup_old_data(
              base_path=Path('data/raw/steam'),
              days_to_keep=30,
              remove_empty_dirs=True
          )

          print(f'ğŸ—‘ï¸  Deleted {result[\"files_deleted\"]} files')
          print(f'ğŸ’¾ Freed {result[\"bytes_freed\"]:,} bytes')
          "

      - name: Commit and push data
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          git add data/

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "ğŸ“­ No new data to commit"
          else
            TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")
            git commit -m "data: hourly collection ${TIMESTAMP}"
            git push
            echo "âœ… Data committed and pushed"
          fi
